{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64900bc5",
   "metadata": {},
   "source": [
    "# Lý thuyết\n",
    "\n",
    "## Ma trận nhầm lẫn (Confusion matrix)\n",
    "  - TP: dương tính thật (dự đoán dương - thực tế dương)\n",
    "  - FP: dương tính giả (dự đoán dương - thực tế âm)\n",
    "  - TN: âm tính thật (dự đoán âm - thực tế âm)\n",
    "  - FN: âm tính giả (dự đoán âm - thực tế dương)\n",
    "\n",
    "$$Accuracy  =  \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "\n",
    "$$Precision = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "$$Recall = \\frac{TP}{TP+FN}$$\n",
    "\n",
    "$$F1 \\ Score = 2 \\frac{Precision *  Recall}{Precision + Recall}$$\n",
    "\n",
    "- ROC - AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5022c1",
   "metadata": {},
   "source": [
    "## Cross Validation (K-Folds) - Phương pháp đánh giá chéo\n",
    "\n",
    "- Sử dụng dữ liệu của traning set chia thành K phần bằng nhau => Huấn luyện mô hình K lần dựa trên traning set, 1 phần làm test set, các phần còn lại làm traning set, sau K lần huấn luyện ta lấy trung bình của K lần để đánh giá hiệu quả của mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb1c0c5",
   "metadata": {},
   "source": [
    "## Cân bằng độ lệch Bias - Phương sai Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aef49e",
   "metadata": {},
   "source": [
    "Good Fit: là nằm giữa Underfitting và Overfitting. Mô hình cho ra kết quả hợp lý với cả tập dữ liệu huấn luyện và các tập dữ liệu mới. Đây là mô hình lý tưởng mang được tính tổng quát và khớp được với nhiều dữ liệu mẫu và cả các dữ liệu mới."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be647c21",
   "metadata": {},
   "source": [
    "Overfit: là mô hình rất hợp lý, rất khớp với tập huấn luyện nhưng khi đem ra dự đoán với dữ liệu mới thì lại không phù hợp. Nguyên nhân có thể do ta chưa đủ dữ liệu để đánh giá hoặc do mô hình của ta quá phức tạp. Mô hình bị quá phức tạp khi mà mô hình của ta sử dụng cả những nhiễu lớn trong tập dữ liệu để học, dấn tới mất tính tổng quát của mô hình (high variance or low  bias). Nếu kết quả training quá tốt đạt tỷ lệ 100\\% thì cần phải xem xét lại dataset vì rất có thể ta đang mắc phải trường hợp overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b9b8cd",
   "metadata": {},
   "source": [
    "Underfit: là hiện tượng mô hình Machine Learning hoặc Deep Learning không học được đủ kiến thức từ dữ liệu huấn luyện và không đạt được hiệu suất tốt trên cả tập huấn luyện và tập kiểm tra (high bias or low variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7619bb1b",
   "metadata": {},
   "source": [
    "### Bias (Độ lệch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1474299d",
   "metadata": {},
   "source": [
    "Định lượng kết quả dự đoán từ mô hình khác nhau như thế nào so với giá trị thật tính trên trung bình => dự doán kết quả, đem so sánh với giá trị thật và tính trung bình sai lệch. Bias được tạo nên do mô hình quá đơn giản => underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9474bea",
   "metadata": {},
   "source": [
    "### Variance (Phương sai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7740cfe9",
   "metadata": {},
   "source": [
    "Độ nhạy của mô hình với độ nhiễu trong dữ liệu huấn luyện. Đo xem dự đoán của mô hình thay đổi như thế nào khi ta thay đổi dữ liệu huấn luyện => mô hình rất phức tạp => overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ca1ecf",
   "metadata": {},
   "source": [
    "### Irreducible error (sai số bản chất)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e5c9e0",
   "metadata": {},
   "source": [
    "Do lấy mẫu sai lệch => không thể can thiệp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce5b09b",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec9345c",
   "metadata": {},
   "source": [
    "Bagging (Bootstrap Aggregating) là một phương pháp Ensemble Learning (học tập kết hợp) được sử dụng trong Machine Learning để nâng cao độ chính xác của mô hình dự đoán. Trong Bagging, chúng ta tạo ra nhiều mô hình dự đoán độc lập với nhau từ các tập dữ liệu con được lấy mẫu ngẫu nhiên với sự thay thế từ tập dữ liệu huấn luyện ban đầu. Sau đó, chúng ta kết hợp các dự đoán của các mô hình này để đưa ra dự đoán cuối cùng."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ea7234",
   "metadata": {},
   "source": [
    "Out of bag (OOB): phần còn sót lại từ mẫu đã lấy => tận dụng những mẫu này làm dữ liệu test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba1ec31",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc62f8ba",
   "metadata": {},
   "source": [
    "Boosting là một quy trình tổng hợp khác để tạo ra một tập hợp các yếu tố dự đoán. Nói cách khác, chúng tôi sắp xếp các cây liên tiếp, thường là các mẫu ngẫu nhiên và ở mỗi bước, mục tiêu là giải quyết sai số thuần từ các cây trước đó.\n",
    "\n",
    "Boosting là một kỹ thuật trong học máy được sử dụng để cải thiện khả năng dự đoán của một thuật toán học máy bằng cách tập trung vào việc học từ các trường hợp khó khăn hơn. Nó hoạt động bằng cách tạo ra các phiên bản của mô hình học máy ban đầu và tập trung vào việc xử lý các trường hợp bị sai lệch của mô hình trước đó, cho đến khi đạt được một mức độ chính xác mong muốn."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
